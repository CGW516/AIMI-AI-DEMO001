# config.py
#ğŸ¤– LLM API é…ç½®
#é€‰é¡¹ 1: Anthropic Claudeï¼ˆæ¨èï¼‰

import os

LLM_CONFIG = {
    "provider": "anthropic",
    "api_key": os.getenv("ANTHROPIC_API_KEY"),  # è®¾ç½®ç¯å¢ƒå˜é‡
    "model": "claude-sonnet-4-20250514",
    "max_tokens": 200,
    "temperature": 0.7
}
#é€‰é¡¹ 2: å›½äº§å¤§æ¨¡å‹ï¼ˆä½æˆæœ¬ï¼‰
# é€šä¹‰åƒé—® / æ–‡å¿ƒä¸€è¨€ / DeepSeek
LLM_CONFIG = {
    "provider": "qwen",
    "api_key": "your_api_key",
    "model": "qwen-turbo",
    "endpoint": "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
}

# è°ƒç”¨ç¤ºä¾‹
import anthropic

client = anthropic.Anthropic(api_key=LLM_CONFIG["api_key"])

async def call_llm(prompt: str):
    with client.messages.stream(
        model=LLM_CONFIG["model"],
        max_tokens=LLM_CONFIG["max_tokens"],
        messages=[{"role": "user", "content": prompt}],
    ) as stream:
        for text in stream.text_stream:
            print(text, end="", flush=True)
            # å®æ—¶å‘é€ç»™ TTS
            await tts_engine.synthesize_chunk(text)